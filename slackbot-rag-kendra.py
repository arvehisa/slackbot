import os
import re

from slack_bolt import App
from slack_bolt.adapter.socket_mode import SocketModeHandler

from langchain.llms import Bedrock
from langchain.chat_models import ChatOpenAI
from langchain.retrievers import AmazonKendraRetriever
from langchain.chains import ConversationalRetrievalChain
from langchain.prompts import PromptTemplate

model_id = os.environ['MODEL_ID']
llm = Bedrock(model_id=model_id,)
#llm = ChatOpenAI(model_name=model_id)

kendra_index_id=os.environ['KENDRA_INDEX_ID']
region=os.environ['AWS_REGION']
retriever = AmazonKendraRetriever(
        index_id=kendra_index_id,
        region_name=region,
#        attribute_filter={
#            "EqualsTo": {
#                "Key": "_language_code",
#                "Value": {"StringValue": "ja"}
#            }
#        },
        verbose=True)

qa_chain = ConversationalRetrievalChain.from_llm(llm=llm, retriever=retriever, verbose=True)

# Slackbot
SLACK_BOT_TOKEN = os.environ['SLACK_BOT_TOKEN']
SOCKET_MODE_TOKEN = os.environ['SOCKET_MODE_TOKEN']
app = App(token=SLACK_BOT_TOKEN)


@app.event("app_mention")
def mention(event, say):
    #メンション部分を除去したメッセージテキスト
    no_mention_text = re.sub(r'^<.*>', '', event['text'])
    chat_history = []
    inputs = {
        "chat_history": chat_history,
        "question": no_mention_text,
    }
    thread_ts = event['ts']
    result = qa_chain(inputs)
    answer = result["answer"]
    
    response = f""" {answer}\n\ngenerated by {model_id}"""
    
    say(text=response, thread_ts=thread_ts)

# サーバーの起動
if __name__ == "__main__":
    handler = SocketModeHandler(app, SOCKET_MODE_TOKEN)
    handler.start()
